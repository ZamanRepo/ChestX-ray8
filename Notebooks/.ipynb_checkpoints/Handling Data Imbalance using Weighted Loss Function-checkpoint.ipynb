{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Handling Data Imbalance using Weighted Loss Function\n",
    "\n",
    "As we know that, one way to avoid having class imbalance impact the loss function is to weight the losses differently. To choose the weights, we first need to calculate the class frequencies.\n",
    "\n",
    "In this notebook, we'll just get the count of each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv file containing training datadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"nih/train-small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count up the number of instances of each class (drop non-class columns from the counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train_df.sum().drop(['Image','PatientId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class Atelectasis has 106 samples\n",
      "The class Cardiomegaly has 20 samples\n",
      "The class Consolidation has 33 samples\n",
      "The class Edema has 16 samples\n",
      "The class Effusion has 128 samples\n",
      "The class Emphysema has 13 samples\n",
      "The class Fibrosis has 14 samples\n",
      "The class Hernia has 2 samples\n",
      "The class Infiltration has 175 samples\n",
      "The class Mass has 45 samples\n",
      "The class Nodule has 54 samples\n",
      "The class Pleural_Thickening has 21 samples\n",
      "The class Pneumonia has 10 samples\n",
      "The class Pneumothorax has 38 samples\n"
     ]
    }
   ],
   "source": [
    "for column in class_counts.keys():\n",
    "    print(f\"The class {column} has {train_df[column].sum()} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot up the distribution of counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(class_counts.values, class_counts.index, color='cyan')\n",
    "plt.title('Distribution of Classes for Training Dataset', fontsize=15)\n",
    "plt.xlabel('Number of Patients', fontsize=15)\n",
    "plt.ylabel('Diseases', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"weighted-loss\"></a>\n",
    "# Weighted Loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of calculating weighted loss.  In the notebook, we will calculate a weighted loss function.  This sample code will give us some intuition for what the weighted loss function is doing, and also help we practice some syntax.\n",
    "\n",
    "For this example, we'll first define a hypothetical set of true labels and then a set of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the 'ground truth' labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: \n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Generate an array of 4 binary label values, 3 positive and 1 negative\n",
    "y_true = np.array(\n",
    "        [[1],\n",
    "         [1],\n",
    "         [1],\n",
    "         [0]])\n",
    "print(f\"y_true: \\n{y_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two models\n",
    "To better understand the loss function, we will pretend that we have two models.\n",
    "- Model 1 always outputs a 0.9 for any example that it's given.  \n",
    "- Model 2 always outputs a 0.1 for any example that it's given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_1: \n",
      "[[0.9]\n",
      " [0.9]\n",
      " [0.9]\n",
      " [0.9]]\n",
      "\n",
      "y_pred_2: \n",
      "[[0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]]\n"
     ]
    }
   ],
   "source": [
    "# Make model predictions that are always 0.9 for all examples\n",
    "y_pred_1 = 0.9 * np.ones(y_true.shape)\n",
    "print(f\"y_pred_1: \\n{y_pred_1}\")\n",
    "print()\n",
    "y_pred_2 = 0.1 * np.ones(y_true.shape)\n",
    "print(f\"y_pred_2: \\n{y_pred_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the regular loss function\n",
    "The learning goal here is to notice that with a regular loss function (not a weighted loss), the model that always outputs 0.9 has a smaller loss (performs better) than model 2.\n",
    "- This is because there is a class imbalance, where 3 out of the 4 labels are 1.\n",
    "- If the data were perfectly balanced, (two labels were 1, and two labels were 0), model 1 and model 2 would have the same loss.  Each would get two examples correct and two examples incorrect.\n",
    "- However, since the data is not balanced, the regular loss function implies that model 1 is better than model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice the shortcomings of a regular non-weighted loss\n",
    "\n",
    "See what loss we get from these two models (model 1 always predicts 0.9, and model 2 always predicts 0.1), see what the regular (unweighted) loss function is for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_reg_1: 2.6187\n"
     ]
    }
   ],
   "source": [
    "loss_reg_1 = -1 * np.sum(y_true * np.log(y_pred_1)) + -1 * np.sum((1 - y_true) * np.log(1 - y_pred_1))\n",
    "print(f\"loss_reg_1: {loss_reg_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_reg_2: 7.0131\n"
     ]
    }
   ],
   "source": [
    "loss_reg_2 = -1 * np.sum(y_true * np.log(y_pred_2)) + -1 * np.sum((1 - y_true) * np.log(1 - y_pred_2))\n",
    "print(f\"loss_reg_2: {loss_reg_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the model 1 always predicts 0.9, the regular loss is 2.6187\n",
      "When the model 2 always predicts 0.1, the regular loss is 7.0131\n"
     ]
    }
   ],
   "source": [
    "print(f\"When the model 1 always predicts 0.9, the regular loss is {loss_reg_1:.4f}\")\n",
    "print(f\"When the model 2 always predicts 0.1, the regular loss is {loss_reg_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the loss function gives a greater loss when the predictions are always 0.1, because the data is imbalanced, and has three labels of `1` but only one label for `0`.\n",
    "\n",
    "Given a class imbalance with more positive labels, the regular loss function implies that the model with the higher prediction of 0.9 performs better than the model with the lower prediction of 0.1\n",
    "Which is not the case as both models are equally bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a weighted loss treats both models the same\n",
    "With a weighted loss function, we will get the same weighted loss when the predictions are all 0.9 versus when the predictions are all 0.1.  \n",
    "- Notice how a prediction of 0.9 is 0.1 away from the positive label of 1.\n",
    "- Also notice how a prediction of 0.1 is 0.1 away from the negative label of 0\n",
    "- So model 1 and 2 are \"symmetric\" along the midpoint of 0.5, if we plot them on a number line between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Loss Equation\n",
    "Calculate the loss for the zero-th label (column at index 0)\n",
    "\n",
    "- The loss is made up of two terms.  To make it easier to read the code, we will calculate each of these terms separately.  We are giving each of these two terms a name for explanatory purposes, but these are not officially called $ \\Large loss_{pos}$ or $ \\Large loss_{neg}$\n",
    "\n",
    "    - $ \\Large loss_{pos}$: we'll use this to refer to the loss where the actual label is positive (the positive examples).\n",
    "    - $ \\Large loss_{neg}$: we'll use this to refer to the loss where the actual label is negative (the negative examples).  \n",
    "\n",
    "$$ \\Large loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\n",
    "\n",
    "$$ \\Large loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)})$$\n",
    "\n",
    "$$  \\Large loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this sample dataset is small enough, we can calculate the positive weight to be used in the weighted loss function.  To get the positive weight, count how many NEGATIVE labels are present, divided by the total number of examples.\n",
    "\n",
    "In this case, there is one negative label, and four total examples.\n",
    "\n",
    "Similarly, the negative weight is the fraction of positive labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining positive and negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive weight w_p: 0.25\n",
      "negative weight w_n 0.75\n"
     ]
    }
   ],
   "source": [
    "# calculate the positive weight as the fraction of negative labels\n",
    "w_p = 1/4\n",
    "\n",
    "# calculate the negative weight as the fraction of positive labels\n",
    "w_n = 3/4\n",
    "\n",
    "print(f\"positive weight w_p: {w_p}\")\n",
    "print(f\"negative weight w_n {w_n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 weighted loss\n",
    "Run the next two cells to calculate the two loss terms separately.\n",
    "\n",
    "Here, `loss_1_pos` and `loss_1_neg` are calculated using the `y_pred_1` predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_pos: 0.0790\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\n",
    "loss_1_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_1 ))\n",
    "print(f\"loss_1_pos: {loss_1_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_neg: 1.7269\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print out the second term in the loss function, which we're calling 'loss_neg'\n",
    "loss_1_neg = -1 * np.sum(w_n * (1 - y_true) * np.log(1 - y_pred_1 ))\n",
    "print(f\"loss_1_neg: {loss_1_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1: 1.8060\n"
     ]
    }
   ],
   "source": [
    "# Sum positive and negative losses to calculate total loss\n",
    "loss_1 = loss_1_pos + loss_1_neg\n",
    "print(f\"loss_1: {loss_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 weighted loss\n",
    "\n",
    "Now do the same calculations for when the predictions are from `y_pred_2'.  Calculate the two terms of the weighted loss function and add them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_2_pos: 1.7269\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\n",
    "loss_2_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_2))\n",
    "print(f\"loss_2_pos: {loss_2_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_2_neg: 0.0790\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print out the second term in the loss function, which we're calling 'loss_neg'\n",
    "loss_2_neg = -1 * np.sum(w_n * (1 - y_true) * np.log(1 - y_pred_2))\n",
    "print(f\"loss_2_neg: {loss_2_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_2: 1.8060\n"
     ]
    }
   ],
   "source": [
    "# Sum positive and negative losses to calculate total loss when the prediction is y_pred_2\n",
    "loss_2 = loss_2_pos + loss_2_neg\n",
    "print(f\"loss_2: {loss_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model 1 and model 2 weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the model always predicts 0.9, the total loss is 1.8060\n",
      "When the model always predicts 0.1, the total loss is 1.8060\n"
     ]
    }
   ],
   "source": [
    "print(f\"When the model always predicts 0.9, the total loss is {loss_1:.4f}\")\n",
    "print(f\"When the model always predicts 0.1, the total loss is {loss_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we notice?\n",
    "Since we used a weighted loss, the calculated loss is the same whether the model always predicts 0.9 or always predicts 0.1.  \n",
    "\n",
    "we may have also noticed that when we calculate each term of the weighted loss separately, there is a bit of symmetry when comparing between the two sets of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_pos: 0.0790 \t loss_1_neg: 1.7269\n",
      "\n",
      "loss_2_pos: 1.7269 \t loss_2_neg: 0.0790\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss_1_pos: {loss_1_pos:.4f} \\t loss_1_neg: {loss_1_neg:.4f}\")\n",
    "print()\n",
    "print(f\"loss_2_pos: {loss_2_pos:.4f} \\t loss_2_neg: {loss_2_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there is a class imbalance, where there are 3 positive labels but only one negative label, the weighted loss accounts for this by giving more weight to the negative label than to the positive label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Loss for more than one class\n",
    "\n",
    "We will now calculate the multi-class weighted loss (when there is more than one disease class that our model is learning to predict).  Here, we can practice working with 2D numpy arrays where there are more than 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the labels (true values) that we will practice with\n",
    "y_true = np.array(\n",
    "        [[1,0],\n",
    "         [1,0],\n",
    "         [1,0],\n",
    "         [1,0],\n",
    "         [0,1]\n",
    "        ])\n",
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing axis=0 or axis=1\n",
    "We will use `numpy.sum` to count the number of times column `0` has the value 0.  \n",
    "First, notice the difference when we set axis=0 versus axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using axis = 0 [4 1]\n",
      "using axis = 1 [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# See what happens when we set axis=0\n",
    "print(f\"using axis = 0 {np.sum(y_true,axis=0)}\")\n",
    "\n",
    "# Compare this to what happens when we set axis=1\n",
    "print(f\"using axis = 1 {np.sum(y_true,axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if we choose `axis=0`, the sum is taken for each of the two columns.  This is what we want to do in this case. If we set `axis=1`, the sum is taken for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the weights\n",
    "Previously, we visually inspected the data to calculate the fraction of negative and positive labels.  Here, we can do this programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the positive weights as the fraction of negative labels (0) for each class (each column)\n",
    "w_p = np.sum(y_true == 0,axis=0) / y_true.shape[0]\n",
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the negative weights as the fraction of positive labels (1) for each class\n",
    "w_n = np.sum(y_true == 1, axis=0) / y_true.shape[0]\n",
    "w_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the assignment, we will train a model to try and make useful predictions.  In order to make this example easier to follow, we will pretend that our model always predicts the same value for every example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model predictions where all predictions are the same\n",
    "y_pred = np.ones(y_true.shape)\n",
    "y_pred[:,0] = 0.3 * y_pred[:,0]\n",
    "y_pred[:,1] = 0.7 * y_pred[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, calculate the two terms that make up the loss function.  Notice that we are working with more than one class (represented by columns).  In this case, there are two classes.\n",
    "\n",
    "Start by calculating the loss for class `0`.\n",
    "\n",
    "$$ \\Large loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\n",
    "\n",
    "$$\\Large loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)})$$\n",
    "\n",
    "$$\\Large loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the zero column for the weights, true values, and predictions that we will use to calculate the loss from the positive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_p[0]: 0.2\n",
      "y_true[:,0]: [1 1 1 1 0]\n",
      "y_pred[:,0]: [0.3 0.3 0.3 0.3 0.3]\n"
     ]
    }
   ],
   "source": [
    "# Print and view column zero of the weight\n",
    "print(f\"w_p[0]: {w_p[0]}\")\n",
    "print(f\"y_true[:,0]: {y_true[:,0]}\")\n",
    "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0_pos: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss from the positive predictions, for class 0\n",
    "loss_0_pos = -1 * np.sum(w_p[0] * \n",
    "                y_true[:, 0] * \n",
    "                np.log(y_pred[:, 0])\n",
    "              )\n",
    "print(f\"loss_0_pos: {loss_0_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the zero column for the weights, true values, and predictions that we will use to calculate the loss from the negative predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_n[0]: 0.8\n",
      "y_true[:,0]: [1 1 1 1 0]\n",
      "y_pred[:,0]: [0.3 0.3 0.3 0.3 0.3]\n"
     ]
    }
   ],
   "source": [
    "# Print and view column zero of the weight\n",
    "print(f\"w_n[0]: {w_n[0]}\")\n",
    "print(f\"y_true[:,0]: {y_true[:,0]}\")\n",
    "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0_neg: 0.2853\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss from the negative predictions, for class 0\n",
    "loss_0_neg = -1 * np.sum( \n",
    "                w_n[0] * \n",
    "                (1 - y_true[:, 0]) * \n",
    "                np.log(1 - y_pred[:, 0])\n",
    "              )\n",
    "print(f\"loss_0_neg: {loss_0_neg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_0: 1.2485\n"
     ]
    }
   ],
   "source": [
    "# add the two loss terms to get the total loss for class 0\n",
    "loss_0 = loss_0_neg + loss_0_pos\n",
    "print(f\"loss_0: {loss_0:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are familiar with the array slicing that we would use when there are multiple disease classes stored in a two-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_pos: 0.2853\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss from the positive predictions, for class 1\n",
    "loss_1_pos = -1 * np.sum(y_true[:, 1] * w_p[1] * np.log(y_pred[:, 1]))\n",
    "print(f'loss_1_pos: {round(loss_1_pos,  4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1_neg: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss from the negative predictions, for class 1\n",
    "loss_1_neg = -1 * np.sum((1-y_true[:, 1]) * w_n[1] * np.log(1-y_pred[:, 1]))\n",
    "print(f'loss_1_neg: {round(loss_1_neg,  4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1: 1.2485\n"
     ]
    }
   ],
   "source": [
    "# add the two loss terms to get the total loss for class 0\n",
    "loss_1 = loss_1_pos + loss_1_neg\n",
    "print(f'loss_1: {round(loss_1,  4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "The data for the two classes (two columns) as well as the predictions were chosen so that we end up getting the same weighted loss for both categories.  \n",
    "\n",
    "In general, we will expect to calculate different weighted loss values for each disease category, as the model predictions and data will differ from one category to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
